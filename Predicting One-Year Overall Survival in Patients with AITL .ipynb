{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6196f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dt = pd.read_csv('yourdata.csv', encoding='gbk')\n",
    "\n",
    "target = 'Dead'\n",
    "predictors = ['Gender', 'Age', 'Ann Arbor staging', 'B symptom','Extranodal involvement', 'ECOG', 'IPI', 'Rash',\n",
    "              'Edema/Serous effusion', 'Hb', 'PLT', 'ALC', 'AEC', 'ALB', 'GLB', 'LDH']\n",
    "\n",
    "seed = 2025\n",
    "X, y = dt[predictors], dt[target]\n",
    "# Divide the training set and the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=seed)\n",
    "\n",
    "print('Total number of train instance: {}'.format(X_train.shape[0]))\n",
    "print('Total number of positive train instance: {}'.format(y_train.sum()))\n",
    "print('Total number of test instance: {}'.format(X_test.shape[0]))\n",
    "print('Total number of positive test instance: {}'.format(y_test.sum()))\n",
    "ratio = float(y_train.value_counts()[0]) / y_train.value_counts()[1]\n",
    "print(ratio)\n",
    "\n",
    "\n",
    "cat_cols = ['Age','B symptom','ECOG','Rash','Edema/Serous effusion','Hb','PLT','ALB']\n",
    "\n",
    "cat_clf = CatBoostClassifier(loss_function=\"Logloss\",\n",
    "                            eval_metric=\"AUC\",\n",
    "                            learning_rate=0.01,\n",
    "                            iterations=1000,\n",
    "                            random_seed=42,\n",
    "                            od_type=\"Iter\",\n",
    "                            depth=4,\n",
    "                            early_stopping_rounds=800,\n",
    "                            colsample_bylevel=0.1,\n",
    "                            l2_leaf_reg=20,\n",
    "                            random_strength=800,\n",
    "                            scale_pos_weight=1,\n",
    "                            silent=True\n",
    "                            )\n",
    "\n",
    "from dhcdatalearn.model_evaluation import EvaModelFusion\n",
    "\n",
    "eva = EvaModelFusion()\n",
    "eva.train(X_train[cat_cols], y_train)\n",
    "names = ['CatBoost']\n",
    "sampling_methods = [cat_clf]\n",
    "\n",
    "# Output the evaluation metric results of the optimized CatBoost model on the training set\n",
    "eva.evalu_models(names, sampling_methods,X_train[cat_cols], y_train)\n",
    "# Output the evaluation metric results of the optimized CatBoost model on the test set\n",
    "eva.evalu_models(names, sampling_methods, X_test[cat_cols], y_test)\n",
    "\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def shap_plot(X_train, X_test, clf, cols, name):\n",
    "    plt.figure(figsize=(25, 20), dpi=1000)\n",
    "    clf.fit(X_train[cols], y_train)\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test[cols])\n",
    "    shap.summary_plot(shap_values, X_test[cols], show=0)\n",
    "    plt.savefig(name, format='png', dpi=1000, bbox_inches='tight',facecolor='white')\n",
    "\n",
    "shap_plot(X_train, X_test, cat_clf, cat_cols, \"shap(Catoost).png\")\n",
    "\n",
    "\n",
    "def shap_plot(X_train, X_test, clf, cols, name):\n",
    "    plt.figure(figsize=(25, 20), dpi=1000)\n",
    "    clf.fit(X_train[cols], y_train)\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test[cols])\n",
    "    shap.summary_plot(shap_values, X_test[cols], plot_type=\"bar\", show=0)\n",
    "    plt.savefig(name, format='png', dpi=1000, bbox_inches='tight',facecolor='white')\n",
    "\n",
    "shap_plot(X_train, X_test, cat_clf, cat_cols, \"shap_bar(Catoost).png\")\n",
    "\n",
    "\n",
    "# LIME\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "from lime import lime_image\n",
    "\n",
    "model = cat_clf\n",
    "model.fit(X_train[cat_cols], y_train)\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(np.array(X_train[cat_cols])), \n",
    "    feature_names=X_train[cat_cols].columns, \n",
    "    class_names=[\"Alive\", \"Dead\"], \n",
    "    mode='classification' \n",
    ")\n",
    "idx = 4\n",
    "data_test = np.array(X_test[cat_cols].iloc[idx]).reshape(1, -1)\n",
    "prediction = model.predict(data_test)[0]\n",
    "y_true = np.array(y_test)[idx]\n",
    "print('Sample{} in the test set, model prediction is {}, true class is {}'.format(idx, prediction, y_true))\n",
    "print(\"\\n\")\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test[cat_cols].iloc[idx], \n",
    "    predict_fn=model.predict_proba,\n",
    "    \n",
    ")\n",
    "cur_y = 'Alive'\n",
    "if y_test.values[idx] == 1 :\n",
    "    cur_y = 'Dead'\n",
    "    \n",
    "print('True outcomeï¼š',cur_y)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3161a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
